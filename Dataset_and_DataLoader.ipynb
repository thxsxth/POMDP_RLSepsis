{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset_and_DataLoader.ipynb",
      "provenance": [],
      "mount_file_id": "1M5a3MqbY5pgpyuZMcn9wmX5eGDdeb7YD",
      "authorship_tag": "ABX9TyPuTUd4d6vVVgk2dOZGuvm8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thxsxth/RLMimic/blob/master/Dataset_and_DataLoader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9vlUk4MKz60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e325277-e39c-480c-8933-a580570eeab9"
      },
      "source": [
        "cd 'drive/My Drive/sepsis3-cohort'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/sepsis3-cohort\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_D6a9b3IXEa",
        "colab_type": "text"
      },
      "source": [
        "## We will test trajectories and analyze any issues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyvv0Qu0K7rA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import random\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import glob\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence,pad_packed_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ_5m6TmXpog",
        "colab_type": "text"
      },
      "source": [
        "### Making the necessary Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3E8hihBLCGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vitals=pd.read_csv('../Vitals/Vitals.csv',parse_dates=['charttime']) #pivoted vitals\n",
        "sofa=pd.read_csv('../pivoted_sofa/pivoted_sofa.csv',parse_dates=['endtime','starttime']) #pivoted sofa\n",
        "labs=pd.read_csv('../pivoted_labs/Pivoted_labs.csv',parse_dates=['charttime'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQU_Lpp_Y6si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vitals['TempC']=vitals['TempC'].ffill()\n",
        "sofa['GCS_min']=sofa['GCS_min'].ffill()\n",
        "labs['icustay_id']=labs['ICUSTAY_ID']\n",
        "sofa[['rate_epinephrine','rate_norepinephrine','rate_dopamine',\t'rate_dobutamine']]=sofa[['rate_epinephrine','rate_norepinephrine','rate_dopamine',\t'rate_dobutamine']].fillna(0)\n",
        "sofa['Vaso']=sofa['rate_epinephrine']+sofa['rate_norepinephrine']+sofa['rate_dobutamine']+sofa['rate_dopamine']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4_y7C46LFwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "co=pd.read_csv('sepsis3_adults.csv',\n",
        "               parse_dates=['intime','outtime','suspected_infection_time_poe']) #cohort + demographics\n",
        "co=co.set_index('icustay_id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlrnOPZCoy_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "admissions=pd.read_csv('admissions.csv',parse_dates=['ADMITTIME','DISCHTIME','DEATHTIME'])\n",
        "admissions=admissions.set_index('icustay_id').sort_index()\n",
        "co['death_time']=admissions['DEATHTIME']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go_qof_zLMhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_cv=pd.read_csv('../Fluids/cleaned_input_cv.csv',parse_dates=['charttime']) \n",
        "input_mv=pd.read_csv('../Fluids/input_eventsMV.csv',parse_dates=['starttime','endtime'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO3e9Vdct6aD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_cv=input_cv[['icustay_id','charttime','tev']]\n",
        "input_mv=input_mv[['icustay_id','endtime','tev']]\n",
        "input_mv['tev_mv']=input_mv['tev']\n",
        "input_mv['charttime']=input_mv['endtime']\n",
        "input_mv=input_mv.drop('tev',axis=1)\n",
        "input_fluids=input_mv.merge(input_cv,on=['icustay_id','charttime'],how='outer')[['icustay_id','charttime','tev','tev_mv']]\n",
        "input_fluids['tev'],input_fluids['tev_mv']=input_fluids['tev'].fillna(0),input_fluids['tev_mv'].fillna(0)\n",
        "input_fluids['volume']=input_fluids['tev']+input_fluids['tev_mv']\n",
        "input_fluids=input_fluids.drop(['tev','tev_mv'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzsgPy8-t-lY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6402eef2-8934-4ce8-8a37-c7fb3fdf3746"
      },
      "source": [
        "input_fluids.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>icustay_id</th>\n",
              "      <th>charttime</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200001</td>\n",
              "      <td>2181-11-25 22:55:00</td>\n",
              "      <td>50.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>200001</td>\n",
              "      <td>2181-11-27 15:47:00</td>\n",
              "      <td>200.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>200001</td>\n",
              "      <td>2181-11-27 23:26:00</td>\n",
              "      <td>250.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>200010</td>\n",
              "      <td>2132-08-05 02:10:00</td>\n",
              "      <td>17.708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>200010</td>\n",
              "      <td>2132-08-05 01:36:00</td>\n",
              "      <td>1000.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   icustay_id           charttime    volume\n",
              "0      200001 2181-11-25 22:55:00    50.000\n",
              "1      200001 2181-11-27 15:47:00   200.000\n",
              "2      200001 2181-11-27 23:26:00   250.000\n",
              "3      200010 2132-08-05 02:10:00    17.708\n",
              "4      200010 2132-08-05 01:36:00  1000.000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R6m1BrTVinm",
        "colab_type": "text"
      },
      "source": [
        "### Let's look at trajectory lengths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOvQMkorI2Ve",
        "colab_type": "text"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFPC9X0aBKuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C1,C2=-0.125,-0.025\n",
        "def get_rewards(df,dead):\n",
        "  \"\"\"\n",
        "  Get's rewards for a trajectory\n",
        "  df_sofa: Pandas Df which contains SOFA scores\n",
        "  MUST BE REINDEXED to have time\n",
        "  dead (bool): If the terminal is survival or death\n",
        "  \"\"\"\n",
        "  # Calculate rewards for SOFA_{t+1} -SOFA_{t}\n",
        "\n",
        "  # rewards1=C1*(df.SOFA_24hours-df.shift().SOFA_24hours).dropna().values\n",
        "  rewards1=C1*(df.SOFA_24hours.values[1:]-df.SOFA_24hours.values[:-1])\n",
        "  # print(rewards1.shape)\n",
        "  \n",
        "  rewards2=C2*((df.shift().SOFA_24hours.iloc[1:]==df.SOFA_24hours.iloc[1:])&(df.SOFA_24hours.iloc[1:]>0)).astype('int').values\n",
        "  # print(rewards2.shape)\n",
        "  \n",
        "  rewards=rewards1+rewards2\n",
        "  # Calculate Terminal rewards\n",
        "  if dead:\n",
        "    rewards=np.concatenate([rewards,[-15]])\n",
        "  else:\n",
        "    rewards=np.concatenate([rewards,[15]])\n",
        "\n",
        "  return torch.FloatTensor(rewards).to(device)\n",
        "  \n",
        "  \n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6znVuNdKvNTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mini_batch_mask(mini_batch, seq_lengths):\n",
        "    mask = torch.zeros(mini_batch.shape[0:2])\n",
        "    for b in range(mini_batch.shape[0]):\n",
        "        mask[b, 0:seq_lengths[b]] = torch.ones(seq_lengths[b])\n",
        "    return mask.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFC2wbj4Wv3v",
        "colab_type": "text"
      },
      "source": [
        "### Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WFvyj1RUsrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "    \n",
        "\n",
        "                             \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "829uvT5xq_FT",
        "colab": {}
      },
      "source": [
        "class patient_dataset(Dataset):\n",
        "  \"\"\"\n",
        "  Implements a dataset for patients\n",
        "  Needs Vitals,Sofa,Inputs,co tables\n",
        "  \"\"\"\n",
        "  def __init__(self,patient_ids,train=True):\n",
        "    #patient_ids :List/np.array\n",
        "    self.ids=patient_ids\n",
        "    self.train=train\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ids)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    #Get Patient from the index\n",
        "    pat=self.ids[idx]\n",
        "    pat_fluids=input_fluids[input_fluids.icustay_id==pat].set_index('charttime')\n",
        "    pat_sofa=sofa[sofa.icustay_id==pat].set_index('endtime')\n",
        "    pat_sofa=pd.concat([pat_sofa,pat_fluids]).resample('H').sum()\n",
        "\n",
        "    pat_vitals=vitals[vitals.icustay_id==pat].set_index('charttime')\n",
        "    pat_labs=labs[labs.icustay_id==pat]\n",
        "    pat_df=pd.concat([pat_vitals,\n",
        "                              pat_sofa]).resample('H').last()[['HeartRate','SysBP','DiasBP',\t'MeanBP','RespRate','SpO2','TempC',\n",
        "                                      'liver_24hours','cardiovascular_24hours',\n",
        "                                      'cns_24hours','renal_24hours','SOFA_24hours','volume','Vaso']].resample('H').last()\n",
        "  \n",
        "    \"\"\"\n",
        "    TO DO: \n",
        "    Implement get_rewards\n",
        "    Get age gender and if they died may be weight height\n",
        "    GET TREATMENTS: Make it Tensor DONE\n",
        "    GET Trajectory Make it Tensor DONE\n",
        "    \"\"\"\n",
        "    dead=co.loc[pat].HOSPITAL_EXPIRE_FLAG==1\n",
        "    if co.loc[pat].HOSPITAL_EXPIRE_FLAG==1:\n",
        "          pat_df=pat_df.truncate(after=co.loc[pat].death_time)\n",
        "\n",
        "    pat_df=pat_df.ffill().dropna()\n",
        "    rewards=get_rewards(pat_df,dead)\n",
        "    treatments=torch.FloatTensor(pat_df[['Vaso','volume']].values).to(device)\n",
        "    trajectory=torch.FloatTensor(pat_df.drop(['Vaso','volume'],axis=1).values).to(device)\n",
        "\n",
        "    return trajectory,treatments, rewards,dead\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM5hzTAWapTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_train(batch_data):\n",
        "\n",
        "  \"\"\"\n",
        "  We will be a list of tuples,\n",
        "  len(list) will be batch_size\n",
        "  (trajectory,treatments,rewards) for each patient in batch\n",
        "  \"\"\"\n",
        "  trajectories=[]\n",
        "  treatments=[]\n",
        "  seq_lens=[]\n",
        "  rewards=[]\n",
        "  dead_=[]\n",
        "\n",
        "  for (trajectory,treatment,reward,dead) in batch_data:\n",
        "\n",
        "    trajectories.append(trajectory) \n",
        "    treatments.append(treatment)\n",
        "    seq_lens.append(trajectory.shape[0])\n",
        "    rewards.append(reward)\n",
        "    dead_.append(dead)\n",
        "\n",
        "  padded_trajectories=pad_sequence(trajectories,batch_first=True)\n",
        "  padded_treatments=pad_sequence(treatments,batch_first=True)\n",
        "  padded_rewards=pad_sequence(rewards,batch_first=True)\n",
        "  mask=get_mini_batch_mask(padded_trajectories,seq_lens)\n",
        "\n",
        "  return padded_trajectories,padded_treatments,padded_rewards,mask,dead_\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}