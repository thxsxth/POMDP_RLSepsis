{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pyro Model_building.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1R7oN8g75EBlnjeCL171UEfXrg8NdvaSP",
      "authorship_tag": "ABX9TyMj88nxi6CQTGf5AfBiaBCq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thxsxth/RLMimic/blob/master/Model/Pyro_Model_building.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJmaUojb4t1P",
        "colab_type": "text"
      },
      "source": [
        "## This Notebook implements A Deep Latent Inference Network for Sepsis Patients.\n",
        "Structured Inference Networks as described by this [paper](https://arxiv.org/abs/1609.09869), is the basis for the implementation, modified to respect causailty and continous observations.\n",
        "\n",
        "Pyro probabilistic language is used for training via Stochastic (Amotized) Variational Inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzI9IYIPXyMW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc05e260-1fb9-409b-bcd3-199aea2ae78a"
      },
      "source": [
        "cd 'drive/My Drive/sepsis3-cohort'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/sepsis3-cohort\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAsw49_5KTLv",
        "colab_type": "text"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8tbgRQNqNGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "b3dcd300-39be-47f3-ae9b-0e788e552e33"
      },
      "source": [
        "!pip install pyro-ppl"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyro-ppl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/77/4db4946f6b5bf0601869c7b7594def42a7197729167484e1779fff5ca0d6/pyro_ppl-1.3.1-py3-none-any.whl (520kB)\n",
            "\u001b[K     |████████████████████████████████| 522kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.5.0+cu101)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (4.41.1)\n",
            "Collecting pyro-api>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/81/957ae78e6398460a7230b0eb9b8f1cb954c5e913e868e48d89324c68cec7/pyro_api-0.1.2-py3-none-any.whl\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (3.2.1)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->pyro-ppl) (0.16.0)\n",
            "Installing collected packages: pyro-api, pyro-ppl\n",
            "Successfully installed pyro-api-0.1.2 pyro-ppl-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8MuB_VsDBYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "cd8a8856-17e1-4ac6-c83f-33b1e5d4e64f"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 16.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 102kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 112kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 122kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 133kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 194kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (47.3.1)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBcFGXolZgIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import random\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import glob\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence,pad_packed_sequence\n",
        "# from tensorboardX import SummaryWriter\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ1hZH9oVKMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "import pyro.poutine as poutine\n",
        "from pyro.distributions import TransformedDistribution\n",
        "from pyro.distributions.transforms import affine_autoregressive\n",
        "from pyro.infer import SVI, JitTrace_ELBO, Trace_ELBO, TraceEnum_ELBO, TraceTMC_ELBO, config_enumerate\n",
        "from pyro.optim import ClippedAdam\n",
        "from modules import Emitter,Gated_Transition,Combiner,Encoder\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZaCVNts5LqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('patientIDs_MIMIC3.csv') as file:\n",
        "   icustays=file.readlines()\n",
        "\n",
        "icustays=[200000+int(x[:-1]) for x in icustays]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-5wH-PP5Rik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00e6e088-d591-4381-d9c1-15fb8067e1fc"
      },
      "source": [
        "icustays[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[200003, 200014, 200030]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kKP6KFrYK6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vitals=pd.read_csv('../Vitals/Vitals.csv',parse_dates=['charttime']) #pivoted vitals\n",
        "sofa=pd.read_csv('../pivoted_sofa/pivoted_sofa.csv',parse_dates=['endtime','starttime']) #pivoted sofa\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHoyKM_6kL1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "co=pd.read_csv('sepsis3_adults.csv',parse_dates=['intime','outtime','suspected_infection_time_poe']) #cohort + demographics"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et9cssVUlx0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_cv=pd.read_csv('../Fluids/cleaned_input_cv.csv',parse_dates=['charttime']) \n",
        "input_mv=pd.read_csv('../Fluids/input_eventsMV.csv',parse_dates=['starttime','endtime'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pfbkiiTcjab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Consider only the cohort\n",
        "vitals=vitals[vitals.icustay_id.isin(set(co.icustay_id))]\n",
        "sofa=sofa[sofa.icustay_id.isin(set(co.icustay_id))]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTqBoFnDdmGq",
        "colab_type": "text"
      },
      "source": [
        "Here we are only considering the cohort defined in https://gitlab.doc.ic.ac.uk/AIClinician/AIClinician"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jBveF_Y5n9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vitals=vitals[vitals.icustay_id.isin(icustays)]\n",
        "sofa=sofa[sofa.icustay_id.isin(icustays)]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr3QZlqZ51cl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6121b62-0b83-4020-b3d5-4fb64b80beb0"
      },
      "source": [
        "len(vitals.icustay_id.unique())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14286"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEEALmllihYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vitals.to_csv('vitals_demo.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjBg29XFa991",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning Dataframes and Creating the Treatment Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noGOsYHQaCwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "sofa[['rate_epinephrine','rate_norepinephrine','rate_dopamine',\t'rate_dobutamine']]=sofa[['rate_epinephrine','rate_norepinephrine','rate_dopamine',\t'rate_dobutamine']].fillna(0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8iYkNZFbXYB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0ab7a7c5-ebd9-4dfd-fb3e-d51ee9dd5b58"
      },
      "source": [
        "sofa['vaso_rate']=sofa['rate_epinephrine']+sofa['rate_norepinephrine']+sofa['rate_dobutamine']+sofa['rate_dopamine']\n",
        "sofa['vaso_rate'].describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    3.821099e+06\n",
              "mean     1.534592e-01\n",
              "std      1.389909e+00\n",
              "min      0.000000e+00\n",
              "25%      0.000000e+00\n",
              "50%      0.000000e+00\n",
              "75%      0.000000e+00\n",
              "max      5.247707e+02\n",
              "Name: vaso_rate, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM0dgE0pcTPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sofa=sofa[['icustay_id','endtime','vaso_rate','rate_norepinephrine','rate_dopamine',\t'rate_dobutamine','urineoutput','cardiovascular_24hours',\t'liver_24hours','cns_24hours',\t'renal_24hours',\t'SOFA_24hours']]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaHCi2x_OCf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cleaning and concatenating Fluid Inputs\n",
        "input_cv=input_cv[['icustay_id','charttime','tev']]\n",
        "input_mv=input_mv[['icustay_id','endtime','tev']]\n",
        "input_mv['tev_mv']=input_mv['tev']\n",
        "input_mv['charttime']=input_mv['endtime']\n",
        "input_mv=input_mv.drop('tev',axis=1)\n",
        "input_fluids=input_mv.merge(input_cv,on=['icustay_id','charttime'],how='outer')[['icustay_id','charttime','tev','tev_mv']]\n",
        "input_fluids['tev'],input_fluids['tev_mv']=input_fluids['tev'].fillna(0),input_fluids['tev_mv'].fillna(0)\n",
        "input_fluids['volume']=input_fluids['tev']+input_fluids['tev_mv']\n",
        "input_fluids=input_fluids[input_fluids.icustay_id.isin(set(co.icustay_id))]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ekc66ncntOH",
        "colab_type": "text"
      },
      "source": [
        "Include age,gender BMI for Vitals df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-37b5bUrmxOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Re Index so it's easier to find\n",
        "co=co.set_index('icustay_id')\n",
        "vitals['age']=co.loc[vitals['icustay_id']]['age'].values\n",
        "vitals['gender']=co.loc[vitals['icustay_id']]['is_male'].values\n",
        "vitals['bmi']=co.loc[vitals['icustay_id']]['bmi'].values\n",
        "vitals['sus_time']=co.loc[vitals['icustay_id']]['suspected_infection_time_poe'].values\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38--ppumVcnY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4de805a8-a4eb-4a0c-a3b1-6f28a28ae3ba"
      },
      "source": [
        "len(vitals[vitals.bmi.notna()].icustay_id.unique()),len(vitals.icustay_id.unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21398, 31211)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uy_63rpQjUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "ea9662fc-4df7-499d-82d9-be1821cf55df"
      },
      "source": [
        "sofa.head(),vitals.head(),co.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   icustay_id             endtime  ...  renal_24hours  SOFA_24hours\n",
              " 0      200001 2181-11-25 19:00:00  ...              2             3\n",
              " 1      200001 2181-11-25 20:00:00  ...              2             3\n",
              " 2      200001 2181-11-25 21:00:00  ...              2             3\n",
              " 3      200001 2181-11-25 22:00:00  ...              2             3\n",
              " 4      200001 2181-11-25 23:00:00  ...              3             4\n",
              " \n",
              " [5 rows x 11 columns],\n",
              "    subject_id  icustay_id           charttime  ...   age  gender       bmi\n",
              " 0       55973      200001 2181-11-25 19:06:00  ...  61.0       0  21.06264\n",
              " 1       55973      200001 2181-11-25 19:07:00  ...  61.0       0  21.06264\n",
              " 2       55973      200001 2181-11-25 19:08:00  ...  61.0       0  21.06264\n",
              " 3       55973      200001 2181-11-25 19:14:00  ...  61.0       0  21.06264\n",
              " 4       55973      200001 2181-11-25 19:16:00  ...  61.0       0  21.06264\n",
              " \n",
              " [5 rows x 14 columns],\n",
              "             Unnamed: 0  hadm_id  excluded  ... abx_poe sepsis-3 sofa>=2\n",
              " icustay_id                                 ...                         \n",
              " 200001               0   152234         1  ...    True        1       1\n",
              " 200003               1   163557         1  ...    True        1       1\n",
              " 200009               4   129607         1  ...    True        1       1\n",
              " 200011               6   121562         1  ...    True        1       1\n",
              " 200014               8   127229         1  ...    True        1       1\n",
              " \n",
              " [5 rows x 51 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2pqqLhWXaeR",
        "colab_type": "text"
      },
      "source": [
        "### Necessary Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7BYBvcD47zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device='cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTw1_0rBq7_8",
        "colab_type": "text"
      },
      "source": [
        "#### Let's define training and validation cohorts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KmpkhwfqhyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training_cohort=np.random.choice(list(co.index),int(0.8*len(list(co.index))),replace=False)\n",
        "# valid_cohort=np.array(list(set(co.index)-set(training_cohort)))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBI_lQ676Oub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training_cohort=np.random.choice(list(vitals.icustay_id.unique()),int(0.8*len(vitals.icustay_id.unique())),replace=False)\n",
        "# valid_cohort=np.array(list((set(vitals.icustay_id.unique())-set(training_cohort))))"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTn8e3m3A_Xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.save('train_cohort',training_cohort)\n",
        "# np.save('valid_cohort',valid_cohort)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btzCeBGmBByu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_cohort=np.load('valid_cohort.npy')\n",
        "training_cohort=np.load('train_cohort.npy')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBoTRdFtfIkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_cohort=np.array(list(set(co.index)-set(training_cohort)))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VoaN4G8BcEr",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qeIwpb6rByv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "699ae563-2047-4f3e-93f3-a4c6e0f9b27a"
      },
      "source": [
        "# set(valid_cohort).intersection(set(training_cohort)),len(training_cohort)+len(valid_cohort)==len(list(co.index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(set(), True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9dodG9t6g85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc0a0aa2-ee04-45ed-f29f-57fe34332077"
      },
      "source": [
        "valid_cohort=list(set(vitals.icustay_id.unique())-set(training_cohort))\n",
        "len(valid_cohort)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2858"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDJB9pJkrH5D",
        "colab_type": "text"
      },
      "source": [
        "So as expected we don't have any common elements, and everything is accounted for"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU7Bm0iB3QAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mini_batch_mask(mini_batch, seq_lengths):\n",
        "    mask = torch.zeros(mini_batch.shape[0:2])\n",
        "    for b in range(mini_batch.shape[0]):\n",
        "        mask[b, 0:seq_lengths[b]] = torch.ones(seq_lengths[b])\n",
        "    return mask.to(device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o7379Vh5a3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataLoader():\n",
        "  \"\"\"\n",
        "  Instance of MyDataLoader class yeilds batches of trajectories , treatments\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self,sofa_df=sofa,vitals_df=vitals,input_df=input_fluids,cohort=co,batch_size=16,icustay_list=training_cohort,train=True):\n",
        "\n",
        "    \"\"\"\n",
        "    sofa_df (pd.Dataframe): Pivoted Sofa Dataframe (Also includes Vasopressors)\n",
        "    vitals (pd.Dataframe): Pivoted vitals\n",
        "    input_df (pd.Dataframe):Input fluids (CV and MV concatanated)\n",
        "    cohort(pd.Dataframe): Cohort Dataframe (contains some demographics)\n",
        "    batch_size (int):batch size\n",
        "    icu_list (iterable): List of patient Ids\n",
        "\n",
        "    \"\"\"\n",
        "   \n",
        "    self.sofa=sofa_df\n",
        "    self.vitals=vitals_df\n",
        "    self.batch_size=batch_size\n",
        "    self.icustays=icustay_list\n",
        "    self.input_fluids=input_df\n",
        "    self.cohort=cohort\n",
        "    self.train=train\n",
        "     \n",
        "    \n",
        "  def __iter__(self):\n",
        "     if self.train:\n",
        "        np.random.shuffle(self.icustays)\n",
        "     patients=self.icustays\n",
        "     for k in range(0,len(patients)-self.batch_size,self.batch_size):\n",
        "          batch_patients=patients[k:k+self.batch_size]   # Iterable containing Batch_size IDS          \n",
        "          treatments=[]\n",
        "          trajectories=[]\n",
        "          seq_lens=[]\n",
        "          \n",
        "          for pat in batch_patients:\n",
        "              temp_v=self.vitals[self.vitals['icustay_id']==pat].set_index('charttime')\n",
        "              temp_sofa=self.sofa[self.sofa['icustay_id']==pat].set_index('endtime')\n",
        "          \n",
        "              # sus_time=self.sus_dict[pat]\n",
        "              ## Get the data points after suspection of infection\n",
        "             \n",
        "              \n",
        "              ## Also need to consider the suspected infection\n",
        "              df=pd.concat([self.vitals[self.vitals.icustay_id==pat].set_index('charttime'),\n",
        "                              self.input_fluids[self.input_fluids.icustay_id==pat].set_index('charttime'),\n",
        "                              self.sofa[self.sofa.icustay_id==pat].set_index('endtime')]).resample('H').last()\n",
        "              # print(df.shape)\n",
        "              df=df.truncate(before=df['sus_time'].values[0])\n",
        "              df=df[['volume','vaso_rate','age','HeartRate','SysBP','DiasBP',\t'MeanBP','RespRate','SpO2',\n",
        "                                      'liver_24hours','cardiovascular_24hours','cns_24hours','renal_24hours','SOFA_24hours']]\n",
        "                        \n",
        "              ## Drop null values (we sill have to hourly sequential structure)\n",
        "              df=df.ffill().dropna()\n",
        "        \n",
        "              if not self.train and  df.shape[0]<1:\n",
        "                   continue\n",
        "              if self.train:\n",
        "                if df.shape[0]>50:\n",
        "                  k=np.random.choice(np.arange(df.shape[0]-50))\n",
        "                  df=df.iloc[k:k+50,]\n",
        "\n",
        "              \n",
        "              trajectories.append(torch.FloatTensor(df[['age','HeartRate','SysBP','DiasBP',\t'MeanBP','RespRate','SpO2',\n",
        "                                      'liver_24hours','cardiovascular_24hours',\n",
        "                                      'cns_24hours','renal_24hours','SOFA_24hours']].values).to(device))           \n",
        "              \n",
        "              actions=df[['vaso_rate','volume']]\n",
        "              treatments.append(torch.FloatTensor(actions.values).to(device))\n",
        "              seq_lens.append(df.shape[0])\n",
        "\n",
        "          padded_trajectories=pad_sequence(trajectories,batch_first=True)\n",
        "          padded_treatments=pad_sequence(treatments,batch_first=True)\n",
        "          mask=get_mini_batch_mask(padded_trajectories,seq_lens)\n",
        "          \n",
        "          yield padded_trajectories,mask, padded_treatments,seq_lens\n",
        "         \n",
        "\n",
        "              \n",
        "\n",
        "         \n",
        "     \n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR1Db6WOtq5b",
        "colab_type": "text"
      },
      "source": [
        "#### Testing the data loader\n",
        "\n",
        "Works when returning lists of trajectories list has length L, and trajectory[i].shape : T*D (D is the Dimension)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-8furvL502G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader= MyDataLoader(batch_size=32)\n",
        "validation_loader=MyDataLoader(batch_size=32,icustay_list=valid_cohort,train=False)\n",
        "test_loader=MyDataLoader(batch_size=32,icustay_list=test_cohort,train=False)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeHijzN-txaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "9675ccb0-6157-4a8c-f783-4a3792a3b20c"
      },
      "source": [
        "for i, (trajectory,mask,treatment,lens) in enumerate(validation_loader):\n",
        "  print('Batch number {}'.format(i))\n",
        "  print(trajectory.shape)\n",
        "  print(treatment.shape)\n",
        "  print(mask.shape)\n",
        "  print(min(lens))\n",
        "  if i==4:\n",
        "    break"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch number 0\n",
            "torch.Size([32, 606, 12])\n",
            "torch.Size([32, 606, 2])\n",
            "torch.Size([32, 606])\n",
            "13\n",
            "Batch number 1\n",
            "torch.Size([29, 545, 12])\n",
            "torch.Size([29, 545, 2])\n",
            "torch.Size([29, 545])\n",
            "11\n",
            "Batch number 2\n",
            "torch.Size([30, 1366, 12])\n",
            "torch.Size([30, 1366, 2])\n",
            "torch.Size([30, 1366])\n",
            "13\n",
            "Batch number 3\n",
            "torch.Size([30, 798, 12])\n",
            "torch.Size([30, 798, 2])\n",
            "torch.Size([30, 798])\n",
            "4\n",
            "Batch number 4\n",
            "torch.Size([30, 1368, 12])\n",
            "torch.Size([30, 1368, 2])\n",
            "torch.Size([30, 1368])\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCIwjiWgbhla",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "022d47c5-b089-40ef-cc88-58b6b4099325"
      },
      "source": [
        "sum(mask[12]),lens[12]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(6., device='cuda:0'), 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wroql9SiyVuE",
        "colab_type": "text"
      },
      "source": [
        "### Defining Model and hyperparamters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tUti-KFT4ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DMM(nn.Module):\n",
        "  \n",
        "  \"\"\"\n",
        "    This PyTorch Module encapsulates the model as well as the\n",
        "    variational distribution (the guide) for the Deep Markov Model\n",
        "\n",
        "    Modified from https://github.com/pyro-ppl/pyro/blob/dev/examples/dmm/dmm.py\n",
        "  \"\"\"\n",
        "  def __init__(self,z_dim,u_dim,x_dim,binary_dim=None,rnn_dim=1024,\n",
        "               hidden_emitter_dim=512,hidden_gated_dim=512,hidden_layers=[16,8,4]\n",
        "               ,num_iafs=0, iaf_dim=50):\n",
        "    \n",
        "    \"\"\"\n",
        "    z_dim (int) : Dimension of the Latent Space\n",
        "    u_dim (int) : Dimension of Action space\n",
        "    x_dim (int) : Dimension of (conitnous) observations\n",
        "    binary_dim (int) : Dimension of binary observations\n",
        "    hidden_layers (iterable): Number of hidden layers for Emitter, transm Encoder respectively\n",
        "    Others should be self explanatory\n",
        "    \"\"\"\n",
        "    \n",
        "    super(DMM,self).__init__()\n",
        "    self.emitter=Emitter(z_dim,x_dim,binary_dim,hidden_emitter_dim,hidden_layers[0])\n",
        "    self.trans=Gated_Transition(z_dim,u_dim, hidden_gated_dim,hidden_layers[1])\n",
        "    self.combiner=Combiner(z_dim,rnn_dim)\n",
        "    self.binary=binary_dim\n",
        "\n",
        "    input_dim=z_dim+u_dim \n",
        "    if binary_dim:\n",
        "      self.rnn=Encoder(x_dim+binary_dim,hidden_dim=rnn_dim,n_layers=hidden_layers[2])\n",
        "    else:\n",
        "      self.rnn=Encoder(x_dim,hidden_dim=rnn_dim,n_layers=hidden_layers[2])\n",
        "    \n",
        "    # if we're using normalizing flows, instantiate those \n",
        "    self.iafs = [affine_autoregressive(z_dim, hidden_dims=[iaf_dim]) for _ in range(num_iafs)]\n",
        "    self.iafs_modules = nn.ModuleList(self.iafs)\n",
        "\n",
        "    # define a (trainable) parameters z_0 and z_q_0 that help define the probability\n",
        "    # distributions p(z_1) and q(z_1)\n",
        "    # (since for t = 1 there are no previous latents to condition on)\n",
        "    \n",
        "    self.z_0 = nn.Parameter(torch.zeros(z_dim))\n",
        "    self.z_q_0 = nn.Parameter(torch.zeros(z_dim))\n",
        "    \n",
        "    # define a (trainable) parameter for the initial hidden state of the rnn\n",
        "    self.h_0 = nn.Parameter(torch.zeros(self.rnn.n_layers, 1, rnn_dim))\n",
        "\n",
        "    if device=='cuda':\n",
        "      self.cuda()\n",
        "\n",
        "\n",
        "\n",
        "    def model(self,batch,batch_lens,actions,mask,binary=None,\n",
        "               annealing_factor=1.0):\n",
        "      \"\"\"\n",
        "      batch : Batch of continous observables: B*T*\n",
        "      binary: Batch of binary observables:\n",
        "      batch_lengths :list\n",
        "      actions : B*T*|A|\n",
        "\n",
        "      \"\"\"\n",
        "      \n",
        "      T_max = batch.size(1)\n",
        "\n",
        "      # set z_prev = z_0 to setup the recursive conditioning in p(z_t | z_{t-1,u_{t-1}})\n",
        "      # and set initial treatment to zero\n",
        "\n",
        "      z_prev = self.z_0.expand(batch.size(0), self.z_0.size(0)) #B*Z_dim\n",
        "      u_prev=torch.zeros(actions.shape[0],actions.shape[2]).to(device)     #B*A\n",
        "      \n",
        "      # we enclose all the sample statements in the model in a plate.\n",
        "      # this marks that each datapoint is conditionally independent of the others\n",
        "      \n",
        "      with pyro.plate(\"z_minibatch\", len(batch)):\n",
        "\n",
        "        for t in pyro.markov(range(1, T_max + 1)):\n",
        "\n",
        "          # the next chunk of code samples z_t ~ p(z_t | z_{t-1},u_{t-1})\n",
        "          # note that (both here and elsewhere) we use poutine.scale to take care of KL annealing\n",
        "\n",
        "          z_mean,z_scale=self.trans(z_prev,u_prev)\n",
        "\n",
        "          with poutine.scale(scale=annealing_factor):              \n",
        "                    z_t = pyro.sample(\"z_%d\" % t,\n",
        "                                      dist.Normal(z_mean, z_scale)\n",
        "                                          .mask(mask[:, t - 1:t])\n",
        "                                          .to_event(1))\n",
        "          \n",
        "          if self.binary:\n",
        "            mu,sigma,binary=self.emitter(z_t)\n",
        "            # change sigma and see if it helps\n",
        "            # sigma=torch.ones_like(mu).to(device)*0.0001\n",
        "          else:\n",
        "            \n",
        "            mu, sigma=self.emitter(z_t)\n",
        "            # sigma=torch.ones_like(mu).to(device)*0.001\n",
        "\n",
        "          pyro.sample(\"cts_x_%d\" % t,\n",
        "                            dist.Normal(mu,sigma)\n",
        "                                .mask(mask[:, t - 1:t])\n",
        "                                .to_event(1),\n",
        "                            obs=batch[:, t - 1, :])\n",
        "          \n",
        "          if self.binary:        \n",
        "               pyro.sample(\"binary_x_%d\" % t,\n",
        "                            dist.Bernoulli(binary)\n",
        "                                .mask(mini_batch_mask[:, t - 1:t])\n",
        "                                .to_event(1),\n",
        "                            obs=binary[:, t - 1, :])\n",
        "          z_prev = z_t\n",
        "          u_prev=actions[:,t-1,:]\n",
        "    \n",
        "    def guide(self,batch,batch_lens,actions,mask,\n",
        "               binary=None,annealing_factor=1.0):\n",
        "      \"\"\"\n",
        "      Need to adjust when using binary observations\n",
        "\n",
        "      \"\"\"\n",
        "      # this is the number of time steps we need to process in the mini-batch\n",
        "      T_max = batch.size(1)\n",
        "      # register all PyTorch (sub)modules with pyro\n",
        "      pyro.module(\"dmm\", self)\n",
        "\n",
        "       # if on gpu we need the fully broadcast view of the rnn initial state\n",
        "       # to be in contiguous gpu memory\n",
        "       \n",
        "      h_0_contig = self.h_0.expand(self.rnn.n_layers, batch.size(0), self.rnn.hidden_dim).contiguous()  #n_layers*B*rnn_hidden\n",
        "      _,rnn_output=self.rnn(batch,batch_lens,h_0_contig)  #rnn_ouput has shape B*T*H\n",
        "       \n",
        "      # set z_prev = z_q_0 to setup the recursive conditioning in q(z_t |...)     \n",
        "      z_prev = self.z_q_0.expand(batch.size(0), self.z_q_0.size(0))\n",
        "      u_prev=torch.zeros(actions.shape[0],actions.shape[2]).to(device)\n",
        "\n",
        "      with pyro.plate(\"z_minibatch\", len(batch)):\n",
        "            \n",
        "            # sample the latents z one time step at a time\n",
        "            # we wrap this loop in pyro.markov so that TraceEnum_ELBO can use multiple samples from the guide at each z\n",
        "            \n",
        "            for t in pyro.markov(range(1, T_max + 1)):\n",
        "                # the next two lines assemble the distribution q(z_t | z_{t-1}, x_{t:T})\n",
        "                \n",
        "                z_loc, z_scale = self.combiner(z_prev, rnn_output[:, t - 1, :])\n",
        "\n",
        "                # if we are using normalizing flows, we apply the sequence of transformations\n",
        "                # parameterized by self.iafs to the base distribution defined in the previous line\n",
        "                # to yield a transformed distribution that we use for q(z_t|...)\n",
        "                \n",
        "                if len(self.iafs) > 0:\n",
        "                    z_dist = TransformedDistribution(dist.Normal(z_loc, z_scale), self.iafs)\n",
        "                    assert z_dist.event_shape == (self.z_q_0.size(0),)\n",
        "                    assert z_dist.batch_shape[-1:] == (len(batch),)\n",
        "                \n",
        "                else:\n",
        "                    z_dist = dist.Normal(z_loc, z_scale)\n",
        "                    assert z_dist.event_shape == ()\n",
        "                    assert z_dist.batch_shape[-2:] == (len(batch), self.z_q_0.size(0))\n",
        "\n",
        "                # sample z_t from the distribution z_dist\n",
        "               \n",
        "                with pyro.poutine.scale(scale=annealing_factor):\n",
        "                    if len(self.iafs) > 0:\n",
        "                        # in output of normalizing flow, all dimensions are correlated (event shape is not empty)\n",
        "                        z_t = pyro.sample(\"z_%d\" % t,\n",
        "                                          z_dist.mask(mask[:, t - 1]))\n",
        "                    \n",
        "                    else:\n",
        "                        # when no normalizing flow used, \".to_event(1)\" indicates latent dimensions are independent\n",
        "                        z_t = pyro.sample(\"z_%d\" % t,\n",
        "                                          z_dist.mask(mask[:, t - 1:t])\n",
        "                                          .to_event(1))\n",
        "                \n",
        "                # the latent sampled at this time step will be conditioned upon in the next time step\n",
        "                # so keep track of it         \n",
        "                z_prev = z_t\n",
        "                u_prev=actions[:,t-1,:]\n",
        "\n",
        "    self.model=model\n",
        "    self.guide=guide\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_annhealing_factor(epoch):\n",
        "  if epoch<10:\n",
        "    return 0.5\n",
        "  else:\n",
        "     return min(1.0,0.25+0.005*epoch)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58WbigvyooUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def validate(batch,batch_lens,actions,masks):\n",
        "    # put the  into evaluation mode (i.e. turn off drop-out if applicable)\n",
        "    dmm.rnn.eval()\n",
        "    dmm.emitter.eval()\n",
        "    dmm.trans.eval()\n",
        "\n",
        "    val_nll = svi.evaluate_loss(dmm,batch,batch_lens,actions,masks\n",
        "                               ) / np.sum(batch_lens)\n",
        "\n",
        "    dmm.rnn.train()\n",
        "    dmm.emitter.train()\n",
        "    dmm.trans.train()\n",
        "    return val_nll"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSQU06c5UNJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\"\"\"### Defining Model and hyperparamters\"\"\"\n",
        "\n",
        "learning_rate=0.00001\n",
        "# learning_rate=25\n",
        "beta1=0.96\n",
        "beta2=0.999\n",
        "clip_norm=20\n",
        "lr_decay=0.99996\n",
        "weight_decay=0.0\n",
        "\n",
        "dmm=DMM(64,2,12)\n",
        "# dmm=DMM(256,2,12,binary_dim=None,rnn_dim=512,\n",
        "#                hidden_emitter_dim=1024,hidden_gated_dim=512,hidden_layers=[16,16,5]\n",
        "#                ,num_iafs=0, iaf_dim=50)\n",
        "N_epochs=5000\n",
        "annhealing_factor=0.5\n",
        "# writer=SummaryWriter(logdir='logs/exp1') #change this as needed\n",
        "# setup optimizer\n",
        "adam_params = {\"lr\": learning_rate, \"betas\": (beta1, beta2),\n",
        "                   \"clip_norm\": clip_norm, \"lrd\": lr_decay,\n",
        "                   \"weight_decay\": weight_decay}\n",
        "optimizer = ClippedAdam(adam_params)\n",
        "# setup inference algorithm\n",
        "svi = SVI(dmm.model, dmm.guide, optimizer, Trace_ELBO())\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5HEP2oEI3uO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULhmaT2jvenQ",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wodx_pmMUd_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "times = [time.time()]\n",
        "for epoch in range(1,N_epochs):\n",
        "  val_nll=0\n",
        "  train_nll=0\n",
        "  val_steps=0\n",
        "  train_steps=0\n",
        "  for i,(batch,masks,actions,batch_lens) in enumerate(train_loader):\n",
        "\n",
        "    if min(batch_lens)==0:\n",
        "      continue\n",
        "\n",
        "\n",
        "    loss = svi.step(dmm,batch=batch,batch_lens=batch_lens,actions=actions,mask=masks,\n",
        "               binary=None,annealing_factor=annhealing_factor)\n",
        "    \n",
        "    # print(loss)\n",
        "    \n",
        "    batch_nll=svi.evaluate_loss(dmm,batch,batch_lens,actions,masks\n",
        "                                 ) / np.sum(batch_lens)\n",
        "    \n",
        "    \n",
        "    train_nll+=batch_nll\n",
        "    train_steps+=1\n",
        "    print(batch_nll)\n",
        "    print('Batch : ', train_steps, ' Training Loss :',train_nll/train_steps,end='')\n",
        "    \n",
        "    \n",
        "     \n",
        "  val_nll=0\n",
        "  val_steps=0\n",
        "  for batch,masks,actions,batch_lens in validation_loader:\n",
        "      if min(batch_lens)==0:\n",
        "          continue\n",
        "      \n",
        "      val_nll+=validate(batch,batch_lens,actions,masks)\n",
        "      print('Validating : ',validate(batch,batch_lens,actions,masks))\n",
        "      val_steps+=1 \n",
        "       \n",
        "      print(val_nll/val_steps) \n",
        "     \n",
        "\n",
        "\n",
        "  print('-'*125)\n",
        "  if val_nll/val_steps<60:\n",
        "    torch.save(dmm.state_dict(),'state_dict_{}.pt'.format(val_nll))\n",
        "  \n",
        "  # writer.add_scalar('train_nll', train_nll/train_steps, epoch)\n",
        "  print('Train nll {}'.format(train_nll/train_steps))\n",
        "  # writer.add_scalar('vall_nll',val_nll/val_steps, epoch)\n",
        "  print('Validation nll {}'.format(val_nll/val_steps))  \n",
        "  annhealing_factor=get_annhealing_factor(epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5l2uJ6uco2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  torch.save(dmm.state_dict(),'state_dict_crazy.pt')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nw_XuM3iEAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20a68261-b4e3-4983-b201-6a6e86ca6d7e"
      },
      "source": [
        "# dmm.load_state_dict(torch.load('state_dict_new.pt',map_location=torch.device('cpu')))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8iFGcL0JSTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}