# -*- coding: utf-8 -*-
"""Models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gZNrmAhB3iV1BN5k6YXgfd1veHW9N-qD

### This notebook defines and test the indiviual modules, and the models
**To do**


*   Need MLP for Emitter : i.e $p(x_t|z_t)$ should output a mean and a log_cov vectors for a Guassian, also need a seperate binomials for binary variables. 
*   $p(z_t|z_{t-1},u_{t-1})$ Gated transitions 
* Guide for the posterior apporximation
* Also need (two?) RNNs to define $G_{\alpha}(z_{t-1},u_{t-1})), F_{\beta}(z_{t-1} ,u_{t-1})$


Let's start with using Pyro for inference

For the moment ignoring the binary parts
"""

import torch
import numpy as np
import pandas as pd
import datetime as dt
import random
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset,DataLoader
import torch.nn.functional as F
import torch.nn.init as weight_init
import os
import glob
from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence,pad_packed_sequence

device='cuda' if torch.cuda.is_available() else 'cpu'

class Emitter(nn.Module):
  """
  A MLP representing  p(x_t|z_t)
  """
  def __init__(self,z_dim,continous_dim,binary_dim=None,hidden_size=128,hidden_layers=2):
    
    super(Emitter,self).__init__()
    
    self.bn=nn.BatchNorm1d(z_dim)
    self.linear=nn.Linear(z_dim,hidden_size)
    self.hidden_layers=nn.ModuleList([nn.Sequential(nn.Linear(hidden_size,hidden_size),nn.ELU()) for i in range(hidden_layers)])
    self.binary_dim=binary_dim
    self.linear_mu=nn.Linear(hidden_size,continous_dim)
    self.linear_sigma=nn.Linear(hidden_size,continous_dim)
    
    if binary_dim:
      self.linear_binary=nn.Linear(hidden_size,binary_dim)

  def forward(self,z):
    """
    z has dimensions #batch_size*hidden_size (B*H)
    """
    z=self.linear(self.bn(z))
    
    for layer in self.hidden_layers:
          z=layer(z)
    
    mu=self.linear_mu(z)
    sigma=F.softplus(self.linear_sigma(z))
    if self.binary_dim:
      binary=F.sigmoid(self.linear_binary(z))
      return mu, sigma,binary

    return mu, sigma

class Gated_Transition(nn.Module):
    """
    Parameterizes the gaussian latent transition probability p(z_t | z_{t-1},u_{t-1})
    using a MLP, where z is latent and u is the action
    Modified from https://pyro.ai/examples/dmm.html

    """
    def __init__(self, z_dim,u_dim, hidden_dim,n_layers=1):
      super(Gated_Transition,self).__init__()
      
      input_dim=z_dim+u_dim
      self.bn=nn.BatchNorm1d(input_dim)
      self.input_to_h=nn.Linear(z_dim+u_dim, hidden_dim)
      self.hidden_layers=nn.ModuleList([nn.Sequential(nn.Linear(hidden_dim,hidden_dim),nn.ELU()) for i in range(n_layers)])
      self.hidden_to_z=nn.Linear(hidden_dim,z_dim)
      
      self.proposed_mean_to_h=nn.Linear(z_dim+u_dim, hidden_dim)
      self.proposed_h_to_z=nn.Linear(hidden_dim,z_dim)

      self.input_to_mean=nn.Linear(z_dim+u_dim,z_dim)
      self.input_to_scale=nn.Linear(z_dim+u_dim,z_dim)
      self.input_to_hid_scale=nn.Linear(z_dim+u_dim,hidden_dim)
      self.hidden_to_scale=nn.Linear(hidden_dim,z_dim)

      self.input_to_mean.bias.data = torch.zeros(z_dim)


    def forward(self,z,u):
  
      """
        Given the latent z_{t-1} and the action u_{t-1}
        
        we return the mean and scale vectors that parameterize the
        (diagonal) gaussian distribution p(z_t | z_{t-1},u_{t-1})
        
        z_t_1 has shape B*D 
        u_t_1 has shape B*T
      """
      # concatenate the latent z and actions along the frequency dimension
      input_=torch.cat([z,u],dim=1)  #B*(D+T) let's call D+T=F
      input_=self.bn(input_)

      #calculate the gate
      # Add hidden layers if necessary
      
      _gate=F.elu(self.input_to_h(input_))
      gate=F.sigmoid(self.hidden_to_z(_gate))
      

      # compute the 'proposed mean'
    
      _proposed_mean = F.elu(self.proposed_mean_to_h(input_))  #B*U_D-->B*H_D   
      for layer in self.hidden_layers:
          _proposed_mean=layer(_proposed_mean)   #B*H_D
    
      proposed_mean = self.proposed_h_to_z(_proposed_mean)  #B*H_D--->B*Z_D
      
      
      
      mean = (1 - gate) * self.input_to_mean(input_) + gate * proposed_mean #B*Z_D
      # mean = gate * proposed_mean #B*Z_D
      
      _scale=F.elu(self.input_to_hid_scale(input_)) #B*F-->B*H
    
      for layer in self.hidden_layers:
        _scale=layer(_scale)     #B*H
      
      scale=F.softplus(self.hidden_to_scale(_scale))   #B*Z_D
                        
      return mean, scale  #B*Z_Dim both

class Encoder(nn.Module):
  """ Encodes x_{:t} for the variational distribution
     adopted  from https://github.com/guxd/deepHMM/blob/master/modules.py#L163
  """

  def __init__(self,input_dim,hidden_dim,n_layers, dropout=0.0, noise_radius=0.2):
      super(Encoder,self).__init__()
      self.rnn=nn.GRU(input_dim,hidden_dim,n_layers,batch_first=True)
      self.dropout=dropout
      self.noise_radius=noise_radius
      self.n_layers=n_layers
      self.hidden_dim=hidden_dim
      
      self.init_h = nn.Parameter(torch.randn(n_layers,1,
                                             hidden_dim), requires_grad=True)
      self.init_weights()

  def  init_weights(self):
        for w in self.rnn.parameters(): # initialize the gate weights with orthogonal
            if w.dim()>1:
                weight_init.orthogonal_(w)

  def forward(self,obs,obs_lens, init_h=None, noise=False):

    """
    obs: A mini batch of observations B*T*D
    obs_lens=observation lengths to pack pad sequences

    """
    batch_size, max_len, freq=obs.size()
    obs=F.dropout(obs,training=self.training)  #B*T*D
    
    obs_lens=torch.LongTensor(obs_lens).to(device)
    obs_lens_sorted, indices = obs_lens.sort(descending=True)
    obs_sorted = obs.index_select(0, indices)  
    
    packed_obs=pack_padded_sequence(obs_sorted,obs_lens_sorted.data.tolist(),batch_first=True)

    if init_h is None:
        init_h = self.init_h.expand(-1,batch_size,-1).contiguous()  

    hids, h_n = self.rnn(packed_obs, init_h) # hids: [B x T x H]  
                                                  # h_n: [num_layers*B*H)
    _, inv_indices = indices.sort()
    hids, lens = pad_packed_sequence(hids, batch_first=True)     
    hids = hids.index_select(0, inv_indices)
    h_n = h_n.index_select(1, inv_indices)

    h_n = h_n.view(self.n_layers,1, batch_size, self.hidden_dim) #[n_layers x n_dirs x batch_sz x hid_sz]
    h_n = h_n[-1] # get the last layer [n_dirs x batch_sz x hid_sz]
    enc = h_n.transpose(0,1).contiguous().view(batch_size,-1) #[batch_sz x (n_dirs*hid_sz)]
     
    if noise and self.noise_radius > 0:
         gauss_noise = torch.normal(means=torch.zeros(enc.size(), device=inputs.device),std=self.noise_radius)
         enc = enc + gauss_noise
            
    return enc, hids


class Combiner(nn.Module):
    """
    Parameterizes `q(z_t | z_{t-1}, x_{:t})`, which is the basic building block
    of the guide (i.e. the variational distribution). The dependence on `x_{:t}` is
    through the hidden state of the RNN (see the PyTorch module `rnn` below)
    """

    def __init__(self, z_dim, rnn_dim):
        super().__init__()
        # initialize the three linear transformations used in the neural network
        self.lin_z_to_hidden = nn.Linear(z_dim, rnn_dim)
        self.lin_hidden_to_loc = nn.Linear(rnn_dim, z_dim)
        self.lin_hidden_to_scale = nn.Linear(rnn_dim, z_dim)
        
        # initialize the two non-linearities used in the neural network
        self.tanh = nn.Tanh()
        self.softplus = nn.Softplus()

    def forward(self, z_t_1, h_rnn):
        """
        Given the latent z at at a particular time step t-1 as well as the hidden
        state of the RNN `h(x_{t:T})` we return the mean and scale vectors that
        parameterize the (diagonal) gaussian distribution `q(z_t | z_{t-1}, x_{t:T})`
        """
        # combine the rnn hidden state with a transformed version of z_t_1
        h_combined = 0.5 * (self.tanh(self.lin_z_to_hidden(z_t_1)) + h_rnn)
        
        # use the combined hidden state to compute the mean used to sample z_t
        loc = self.lin_hidden_to_loc(h_combined)
        
        # use the combined hidden state to compute the scale used to sample z_t
        scale = self.softplus(self.lin_hidden_to_scale(h_combined))
        
        # return loc, scale which can be fed into Normal
        return loc, scale


"""## Main Module in Pyro"""

class DMM(nn.Module):
  
  """
    This PyTorch Module encapsulates the model as well as the
    variational distribution (the guide) for the Deep Markov Model

    Modified from https://github.com/pyro-ppl/pyro/blob/dev/examples/dmm/dmm.py
  """
  def __init__(self,z_dim,u_dim,x_dim,binary_dim=None,rnn_dim=600,
               hidden_emitter_dim=128,hidden_gated_dim=128,hidden_layers=[2,1,2]
               ,num_iafs=0, iaf_dim=50):
    
    super(DMM,self)__init__()
    
    self.emitter=Emitter(z_dim,x_dim,binary_dim,hidden_emitter_dim,hidden_layers[0])
    self.trans=Gated_Transition(z_dim,u_dim, hidden_gated_dim,hidden_layers[1])
    self.combiner=Combiner(z_dim,rnn_dim)
    self.binary=binary_dim

    input_dim=z_dim+u_dim ##Check this
    self.rnn=Encoder(x_dim,hidden_dim=rnn_dim,n_layers=hidden_layers[2])
    
    # if we're using normalizing flows, instantiate those too
    self.iafs = [affine_autoregressive(z_dim, hidden_dims=[iaf_dim]) for _ in range(num_iafs)]
    self.iafs_modules = nn.ModuleList(self.iafs)

    # define a (trainable) parameters z_0 and z_q_0 that help define the probability
    # distributions p(z_1) and q(z_1)
    # (since for t = 1 there are no previous latents to condition on)
    
    self.z_0 = nn.Parameter(torch.zeros(z_dim))
    self.z_q_0 = nn.Parameter(torch.zeros(z_dim))
    
    # define a (trainable) parameter for the initial hidden state of the rnn
    self.h_0 = nn.Parameter(torch.zeros(self.rnn.n_layers, 1, rnn_dim))

    if device=='cuda':
      self.cuda()


    def model(self,batch,batch_lens,binary,actions,mask,
               annealing_factor=1.0):
      """
      batch : Batch of continous observables: B*T*
      binary: Batch of binary observables:
      batch_lengths :list
      actions : B*T*|A|

      """"
      
      T_max = batch.size(1)

      # set z_prev = z_0 to setup the recursive conditioning in p(z_t | z_{t-1,u_{t-1}})
      # and set initial treatment to zero

      z_prev = self.z_0.expand(batch.size(0), self.z_0.size(0)) #B*Z_dim
      u_prev=torch.zeros(u.shape[0],u.shape[2]).to(device)     #B*A
      
      # we enclose all the sample statements in the model in a plate.
      # this marks that each datapoint is conditionally independent of the others
      
      with pyro.plate("z_minibatch", len(batch)):

        for t in pyro.markov(range(1, T_max + 1)):

          # the next chunk of code samples z_t ~ p(z_t | z_{t-1},u_{t-1})
          # note that (both here and elsewhere) we use poutine.scale to take care of KL annealing

          z_mean,z_scale=self.trans(z_prev,u_prev)

          with poutine.scale(scale=annealing_factor):              
                    z_t = pyro.sample("z_%d" % t,
                                      dist.Normal(z_mean, z_scale)
                                          .mask(mask[:, t - 1:t])
                                          .to_event(1))
          
          mu, sigma, binary=self.emitter(z_prev)

          pyro.sample("cts_x_%d" % t,
                            dist.Normal(mu,sigma)
                                .mask(mask[:, t - 1:t])
                                .to_event(1),
                            obs=batch[:, t - 1, :])
          
          if self.binary:        
               pyro.sample("binary_x_%d" % t,
                            dist.Bernoulli(binary)
                                .mask(mini_batch_mask[:, t - 1:t])
                                .to_event(1),
                            obs=binary[:, t - 1, :])
           z_prev = z_t
           u_prev=actions[:,t-1,:]
    
    def guide(self,batch,batch_lens,binary=None,actions,mask,
               annealing_factor=1.0):
      """
      Need to adjust when using binary observations

      """
       # this is the number of time steps we need to process in the mini-batch
       T_max = batch.size(1)
       # register all PyTorch (sub)modules with pyro
       pyro.module("dmm", self)

       # if on gpu we need the fully broadcast view of the rnn initial state
       # to be in contiguous gpu memory
       
       h_0_contig = self.h_0.expand(1, batch.size(0), self.rnn.hidden_size).contiguous()  #1*B*rnn_hidden
       _,rnn_output=self.rnn(batch,batch_lens,h_0_contig)  #rnn_ouput has shape B*T*H
       
       # set z_prev = z_q_0 to setup the recursive conditioning in q(z_t |...)     
       z_prev = self.z_q_0.expand(batch.size(0), self.z_q_0.size(0))
       u_prev=torch.zeros(u.shape[0],u.shape[2]).to(device)

       with pyro.plate("z_minibatch", len(batch)):
            
            # sample the latents z one time step at a time
            # we wrap this loop in pyro.markov so that TraceEnum_ELBO can use multiple samples from the guide at each z
            
            for t in pyro.markov(range(1, T_max + 1)):
                # the next two lines assemble the distribution q(z_t | z_{t-1}, x_{t:T})
                
                z_loc, z_scale = self.combiner(z_prev, rnn_output[:, t - 1, :])

                # if we are using normalizing flows, we apply the sequence of transformations
                # parameterized by self.iafs to the base distribution defined in the previous line
                # to yield a transformed distribution that we use for q(z_t|...)
                
                if len(self.iafs) > 0:
                    z_dist = TransformedDistribution(dist.Normal(z_loc, z_scale), self.iafs)
                    assert z_dist.event_shape == (self.z_q_0.size(0),)
                    assert z_dist.batch_shape[-1:] == (len(batch),)
                
                else:
                    z_dist = dist.Normal(z_loc, z_scale)
                    assert z_dist.event_shape == ()
                    assert z_dist.batch_shape[-2:] == (len(batch), self.z_q_0.size(0))

                # sample z_t from the distribution z_dist
               
                with pyro.poutine.scale(scale=annealing_factor):
                    if len(self.iafs) > 0:
                        # in output of normalizing flow, all dimensions are correlated (event shape is not empty)
                        z_t = pyro.sample("z_%d" % t,
                                          z_dist.mask(mask[:, t - 1]))
                    
                    else:
                        # when no normalizing flow used, ".to_event(1)" indicates latent dimensions are independent
                        z_t = pyro.sample("z_%d" % t,
                                          z_dist.mask(mask[:, t - 1:t])
                                          .to_event(1))
                
                # the latent sampled at this time step will be conditioned upon in the next time step
                # so keep track of it         
                z_prev = z_t
                u_prev=actions[:,t-1,:]



